{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f863fa34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2451f457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_rows', 10000)    \n",
    "# pd.set_option('display.max_columns', 500)  # これらを実行するとDataFrameを出力する際に省略されずにすべて表示されるようになる(重くなる)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4c78ab",
   "metadata": {},
   "source": [
    "## 保存先の設定\n",
    "\n",
    "user_id: 自身のユーザーID\n",
    "workspace: jupyterをマウントしたディレクトリ(run_jupyter内の--notebook-dirに指定されているディレクトリ)から、保存先ディレクトリへの相対パス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4d0ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = \"u01094\"                                \n",
    "workspace = \"workspace/mizuho/work/processed_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e877398c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"/home/u00232/dss/share24S/mizuho/work/processed_data\" # 変更の必要なし\n",
    "data_dir = \"提供データ\"                                           # 提供データ or 運用結果計算例\n",
    "save_dir = os.path.join(\"/home\", user_id, workspace)              # 保存先ディレクトリ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa46970",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"学習用データ.xlsx\", \"train_indicator_data.csv\"] # 処理を行うファイル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93e44d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ディレクトリ内のすべてのファイルを取得\n",
    "# files = [file for file in os.listdir(os.path.join(base_dir, data_dir))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bacb47",
   "metadata": {},
   "source": [
    "## データ処理用にファイルの読み込み、書き出しを行う関数\n",
    "\n",
    "引数のprocess_funcを変更することで、自由な処理を行える"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16b41ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_process_save(method, process_func):\n",
    "    for file in files:\n",
    "        # splitextは例えば\"example.txt\"を \"example\", \".txt\"として返す\n",
    "        base_name, extension = os.path.splitext(file)\n",
    "        if extension not in [\".xlsx\", \".csv\"]:\n",
    "            raise ValueError(\"extension can only be 'xlsx' or 'csv'\")\n",
    "\n",
    "        file_path = os.path.join(base_dir, data_dir, file)\n",
    "\n",
    "        # ファイルを読み込む\n",
    "        print(f\"reading '{file_path}' ...\")\n",
    "        if extension == \".xlsx\":\n",
    "            df = pd.read_excel(file_path, header=6)\n",
    "        else:\n",
    "            df = pd.read_csv(file_path, header=6, sep=';')\n",
    "\n",
    "        # NaNを削除するなどの処理を行う\n",
    "        print(\"processing ...\")\n",
    "        processed_df = process_func(df)\n",
    "\n",
    "        # 出力ファイル名を設定(csv)\n",
    "        output_dir = os.path.join(save_dir, method)\n",
    "        output_file = os.path.join(output_dir, base_name + \".csv\")\n",
    "\n",
    "        # 出力ディレクトリを作成\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        # 整形データを別ファイルに出力\n",
    "        processed_df.to_csv(output_file, index=False)\n",
    "\n",
    "        print(\"saved to \" + output_file)\n",
    "        display(processed_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504dfd76",
   "metadata": {},
   "source": [
    "## 処理用の関数\n",
    "\n",
    "上であげたprocess_func。\n",
    "DataFrameを受け取って自由に処理を施し、DataFrameを返す。\n",
    "例として3つ挙げている。\n",
    "\n",
    "- delete_all_nan_columns: すべてがNaNのカラムをすべて削除する\n",
    "- delete_all_nan: すべてがNaNのカラムを削除したのち、一つでもNaNの存在するレコードを削除する\n",
    "- delete_any_nan_columns: 一つでもNaNの存在するカラムをすべて削除する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583575dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_all_nan_columns(df):\n",
    "        # NaNのみのカラムを削除\n",
    "        processed_df = df.dropna(axis=1, how='all')\n",
    "        \n",
    "        return processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c560a304",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_all_nan(df):\n",
    "        # NaNのみのカラムを削除\n",
    "        df_droped_all_nan_columns = df.dropna(axis=1, how='all')\n",
    "\n",
    "        # NaNが存在しないレコードを削除\n",
    "        df_droped_all_nan = df_droped_all_nan_columns.dropna()\n",
    "        \n",
    "        return df_droped_all_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64b4642",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_any_nan_columns(df):\n",
    "    df_droped_any_nan_columns = df.dropna(axis=1)\n",
    "    \n",
    "    return df_droped_any_nan_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321ded58",
   "metadata": {},
   "source": [
    "## 実行方法\n",
    "\n",
    "read_process_save関数に、\n",
    "\n",
    "1. 保存ディレクトリの名前 (method)\n",
    "2. 処理用の関数           (process_func)\n",
    "\n",
    "の二つの引数を渡すと\n",
    "\n",
    "save_dir内のmethodディレクトリに保存される"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5511048d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# すべてがNaNであるカラムをすべて削除\n",
    "\n",
    "read_process_save(\"delete_all_nan_columns\", delete_all_nan_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ade35ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# すべてがNaNであるカラムを削除し、NaNが一つでも存在するレコードをすべて削除\n",
    "\n",
    "read_process_save(\"delete_all_nan\", delete_all_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b444469d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaNが一つでも存在するカラムをすべて削除\n",
    "\n",
    "read_process_save(\"delete_any_nan_columns\", delete_any_nan_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9019aa",
   "metadata": {},
   "source": [
    "## おまけ\n",
    "\n",
    "レコードを削除してしまう手法を用いると、評価用のデータとずれが生じてしまうため、Datesカラムを参照して一致するデータのみを新たな評価用データとして保存する\n",
    "\n",
    "train_validation_match は二重配列で、[train_data, validataion_data]の組のリスト\n",
    "\n",
    "filter_validation_by_train_dates関数には、read_process_save関数に渡したmethodを渡す。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6866a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_validation_match = [[\"学習用データ.xlsx\", \"学習用正解ラベル.xlsx\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79f755c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_validation_by_train_dates(method):\n",
    "    for train_file, validation_file in train_validation_match:\n",
    "        # splitextは例えば\"example.txt\"を \"example\", \".txt\"として返す\n",
    "        _, train_extension = os.path.splitext(train_file)\n",
    "        if train_extension not in [\".xlsx\", \".csv\"]:\n",
    "            raise ValueError(\"train extension can only be 'xlsx' or 'csv'\")\n",
    "            \n",
    "        train_path = os.path.join(save_dir, method, train_file)\n",
    "\n",
    "        # trainファイルを読み込む\n",
    "        print(f\"reading train file '{train_path}' ...\")\n",
    "        if train_extension == \".xlsx\":\n",
    "            train_df = pd.read_excel(train_path)\n",
    "        else:\n",
    "            train_df = pd.read_csv(train_path, sep=';')\n",
    "        \n",
    "        validation_base_name, validation_extension = os.path.splitext(validation_file)\n",
    "        if validation_extension not in [\".xlsx\", \".csv\"]:\n",
    "            raise ValueError(\"validation extension can only be 'xlsx' or 'csv'\")\n",
    "            \n",
    "        validation_path = os.path.join(base_dir, data_dir, validation_file)\n",
    "\n",
    "        # validationファイルを読み込む\n",
    "        print(f\"reading validation file '{validation_path}' ...\")\n",
    "        if validation_extension == \".xlsx\":\n",
    "            validation_df = pd.read_excel(validation_path)\n",
    "        else:\n",
    "            validation_df = pd.read_csv(validation_path, sep=';')\n",
    "                \n",
    "        # validationにおいて、trainに残っているDatesに一致する行のみを抽出する\n",
    "        print(\"filtering validation data by date ...\")\n",
    "        train_dates = train_df[\"Dates\"]\n",
    "        filtered_validation_df = validation_df[validation_df[\"Dates\"].isin(train_dates)]\n",
    "        \n",
    "        # 出力ファイル名を設定(csv)\n",
    "        output_dir = os.path.join(save_dir, method)\n",
    "        output_file = os.path.join(output_dir, validation_base_name + \".csv\")\n",
    "\n",
    "        # 整形データを別ファイルに出力\n",
    "        filtered_validation_df.to_csv(output_file, index=False)\n",
    "\n",
    "        print(\"saved to \" + output_file)\n",
    "        display(filtered_validation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09a8dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_validation_by_train_dates(\"delete_all_nan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b2b1b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
